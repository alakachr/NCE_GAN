{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from math import pi\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from  sklearn import mixture\n",
    "import scipy.sparse\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import multivariate_normal\n",
    "tfd = tfp.distributions\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pm0(x, m, s):\n",
    "    mvn = tfd.MultivariateNormalFullCovariance(\n",
    "    loc=m,\n",
    "    covariance_matrix=s)\n",
    "    k = len(m)\n",
    "    return np.sqrt(np.linalg.det(s)*(2*pi)**k)*mvn.prob(x);\n",
    "\n",
    "\n",
    "def pn(x, m0, s0):\n",
    "    mvn = tfd.MultivariateNormalFullCovariance(\n",
    "    loc=m0,\n",
    "    covariance_matrix=s0)\n",
    "    \n",
    "    return mvn.prob(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gradient:\n",
    "\n",
    "\n",
    "    # instance attribute\n",
    "    def __init__(self, cte,mu,sigma, error_mu,error_sigma, error_cte, ctes,mus,sigmas):\n",
    "        self.cte = cte\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        self.error_mu = error_mu\n",
    "        self.error_sigma = error_sigma\n",
    "        self.error_cte = error_cte \n",
    "        \n",
    "        self.ctes = ctes\n",
    "        self.mus = mus\n",
    "        self.sigmas = sigmas\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_f2():\n",
    "    \n",
    "    g1= a*Z1 + b*Z2 + mu[0]\n",
    "    g2 = c*Z1 +  d*Z2 + mu[1]\n",
    "\n",
    "    \n",
    "\n",
    "    g= tf.stack([g1,g2],1)\n",
    "\n",
    "\n",
    "    p_n = pn( g,m0, S) # noise (generator) density \n",
    "    p_m = pm0(g, m_data, s_data) #data density\n",
    "    return tf.math.reduce_mean( tf.math.log(p_n/(cte*p_m+p_n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\envs\\memoiregan\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\distribution.py:284: MultivariateNormalFullCovariance.__init__ (from tensorflow_probability.python.distributions.mvn_full_covariance) is deprecated and will be removed after 2019-12-01.\n",
      "Instructions for updating:\n",
      "`MultivariateNormalFullCovariance` is deprecated, use `MultivariateNormalTriL(loc=loc, scale_tril=tf.linalg.cholesky(covariance_matrix))` instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "######## ALTERNATIVE VERSION #############\n",
    "\n",
    "# d =2\n",
    "m_data = [1,2]\n",
    "s_data = [[2.0, 0.5], [0.5, 3]]\n",
    "\n",
    "batch_size=100\n",
    "x_batches = multivariate_normal.rvs(m_data, s_data, 10,batch_size)\n",
    "\n",
    "\n",
    "mu_init = [1, 2]\n",
    "a,b,c,d =  tf.Variable((1+1.41421356), dtype=\"float32\"), tf.Variable(1+0, dtype=\"float32\"), tf.Variable(1+0.35355339, dtype=\"float32\"), tf.Variable(1+1.6955825 ,dtype=\"float32\")\n",
    "cte_init = 1\n",
    "\n",
    "mu = tf.Variable(mu_init, dtype=\"float32\")\n",
    "\n",
    "cte = cte_init\n",
    "error_mu = [] \n",
    "error_sigma = []\n",
    "\n",
    "\n",
    "error_cte = [] \n",
    "\n",
    "mus = []\n",
    "sigmas = []\n",
    "\n",
    "\n",
    "ctes = []\n",
    "max_iters = 500\n",
    "learning_rate = 0.01\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    " \n",
    "for itr in range(max_iters): \n",
    "    #print(itr)\n",
    "    for x in x_batches:\n",
    "        ctes.append(cte)\n",
    "        Z1 = np.array(random.normal( 0, 1,batch_size)).astype(\"float32\")\n",
    "        Z2 = np.array(random.normal( 0, 1,batch_size)).astype(\"float32\")\n",
    "        \n",
    "        g1= a*Z1 + b*Z2 + mu[0]\n",
    "        g2 = c*Z1 +  d*Z2 + mu[1]\n",
    "\n",
    "        A = np.array([[a,b],[c,d]])\n",
    "        S = np.array(np.matmul(A , np.transpose(A))).astype(\"float32\")\n",
    "        \n",
    "       \n",
    "\n",
    "        g= np.stack([g1,g2],1)\n",
    "        \n",
    "       \n",
    "        \n",
    "        m0 = mu.numpy()\n",
    "        \n",
    "        p_nx = pn( x,m0, S).numpy() # noise (generator) density \n",
    "        p_mx = pm0(x, m_data, s_data).numpy() #data density\n",
    "\n",
    "        \n",
    "        p_ng = pn( g,m0, S).numpy() # noise (generator) density \n",
    "        p_mg = pm0(g, m_data, s_data).numpy() #data density\n",
    "\n",
    "        grad_cte = 1/cte - p_mx/(cte*p_mx+p_nx) -  p_mg/(cte*p_mg+p_ng)\n",
    "        grad_cte = np.sum(grad_cte)/batch_size\n",
    "            \n",
    "        \n",
    "        cte = cte + 0.01*grad_cte\n",
    "        \n",
    "#         print(\"gradient   \" , grad_cte )\n",
    "#         print(\"cte\" , cte)\n",
    "        error_cte.append( (grad_cte) ) \n",
    "        if np.isnan(grad_cte):\n",
    "            break\n",
    "            \n",
    "        opt.minimize(obj_f2, var_list=[a,b,c,d])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 170.0, x1 = 10.0, x2 = 10.0\n",
      "y = 141.3, x1 = 8.1, x2 = 10.0\n",
      "y = 123.6, x1 = 6.6, x2 = 10.0\n",
      "y = 112.7, x1 = 5.4, x2 = 10.0\n",
      "y = 106.1, x1 = 4.4, x2 = 10.0\n",
      "y = 102.2, x1 = 3.6, x2 = 10.0\n",
      "y = 100.0, x1 = 3.0, x2 = 10.0\n",
      "y = 98.7, x1 = 2.5, x2 = 10.0\n",
      "y = 98.1, x1 = 2.1, x2 = 10.0\n",
      "y = 97.8, x1 = 1.8, x2 = 10.0\n",
      "y = 97.8, x1 = 1.5, x2 = 10.0\n",
      "y = 97.8, x1 = 1.3, x2 = 10.0\n",
      "y = 97.9, x1 = 1.2, x2 = 10.0\n",
      "y = 98.0, x1 = 1.0, x2 = 10.0\n",
      "y = 98.1, x1 = 0.9, x2 = 10.0\n",
      "y = 98.2, x1 = 0.8, x2 = 10.0\n",
      "y = 98.3, x1 = 0.8, x2 = 10.0\n",
      "y = 98.4, x1 = 0.7, x2 = 10.0\n",
      "y = 98.4, x1 = 0.7, x2 = 10.0\n",
      "y = 98.5, x1 = 0.6, x2 = 10.0\n",
      "y = 98.5, x1 = 0.6, x2 = 10.0\n",
      "y = 98.6, x1 = 0.6, x2 = 10.0\n",
      "y = 98.6, x1 = 0.6, x2 = 10.0\n",
      "y = 98.6, x1 = 0.6, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n",
      "y = 98.7, x1 = 0.5, x2 = 10.0\n"
     ]
    }
   ],
   "source": [
    "x1 = tf.Variable(10.0, dtype =\"double\")\n",
    "x1, x2 = reset()\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "for i in range(50):\n",
    "\tprint ('y = {:.1f}, x1 = {:.1f}, x2 = {:.1f}'.format(fu(x1, x2).numpy(), x1.numpy(), x2.numpy()))\n",
    "\topt.minimize(fu_minimzie, var_list=[x1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
