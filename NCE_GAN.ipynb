{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from function_memoire import *\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M√©moire NCE-GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I ) NCE for a 1D distribution\n",
    "\n",
    "Data $X \\sim  N(m,s)$\n",
    "\n",
    "Noise $Y \\sim  Q = \\mu +\\sigma N(0,1)$ with $\\mu, \\sigma$ fixed (in the code it is fixed at mu_unit and sigma_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets experiment NCE with different values of $\\mu_{data}, \\sigma_{data} , \\mu_{noise}, \\sigma_{noise}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cas 1 : Loi du bruit tr√®s distincte de l'√©chantillon: \n",
    "* ( mu_data = 12, sigma _data= 1 ////VS//// mu_noise=24 , sigma_noise = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fini √† la  265  iteration\n",
      "fini √† la  282  iteration\n",
      "fini √† la  68  iteration\n",
      "----------------------------  -----------\n",
      "quadratic error                  0.165064\n",
      "Variance estim                   0.310581\n",
      "Number of Iterations Average  4119\n",
      "----------------------------  -----------\n",
      "true constant value 0.3989422804014327\n",
      " nbre d'it√©rations 691\n"
     ]
    }
   ],
   "source": [
    "mupo = 12\n",
    "sigmapo = 1\n",
    "batch_size=100\n",
    "X = random.normal(mupo, sigmapo, 1000)\n",
    "x_batches = np.reshape(X, (10, batch_size)) \n",
    "\n",
    "est_const=[]\n",
    "nb_it=[]\n",
    "\n",
    "for i in range(10):\n",
    "    grad=NCEDescent1D(x_batches, mupo, sigmapo,mu_init = 24, sigma_init=4, cte_init = 5, learning_rate = [1,0.01], max_iters = 500, nu =1)    \n",
    "    est_const.append(grad.cte)\n",
    "    nb_it.append(len(grad.ctes))\n",
    "    \n",
    "quad_error = np.mean(np.array(est_const) - 1/(sqrt(2*pi)*sigmapo) )\n",
    "var_estim = np.var(np.array(est_const))\n",
    "mean_it = np.mean(np.array(nb_it))\n",
    "\n",
    "tab=[['quadratic error', quad_error],['Variance estim', var_estim],['Number of Iterations Average',mean_it]]\n",
    "\n",
    "print(tabulate(tab))\n",
    "print(\"true constant value\" , 1/(sqrt(2*pi)*sigmapo) )    \n",
    "#print(\"constant estimate\",grad.cte)\n",
    "print(\" nbre d'it√©rations\", len(grad.ctes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remarques :\n",
    "* 1) L'algorithme est tr√®s sensible √† l'initialisation. Pour C0= 5, donc loin de la vraie constante, il faut prendre un pas assez grand (ici =1) afin d'esp√©rer converger. √† titre d'exemple avec un pas = 0,1 on converge jamais.Ceci est surement du au support des lois dont l'approximation num√©riques implique une tr√®s faible variation du gradient.\n",
    "* 2) Quand l'algorithme converge sa variance semble plutot grande en lan√ßant le code √† plusieurs reprises, avec une estimation hasardeuse ( ne converge pas, ou reste eloign√©e de la situation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impact de nu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mupo = 2\n",
    "sigmapo = 0.2\n",
    "batch_size=100\n",
    "X = random.normal(mupo, sigmapo, 1000)\n",
    "x_batches = np.reshape(X, (10, batch_size)) \n",
    "x= np.linspace(1,100,num=50)\n",
    "\n",
    "ctes=[]\n",
    "V=[]\n",
    "C = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    \n",
    "    for j in range(10):\n",
    "        \n",
    "        grad = NCEDescent1D(x_batches,mupo, sigmapo,mu_init = 24, sigma_init=4, cte_init = 0.2, learning_rate = [0.01,0.01], max_iters = 100, nu =x[i])\n",
    "        #print(grad.m0)\n",
    "        ctes.append(grad.cte)\n",
    "    \n",
    "    C.append(np.mean(grad.cte))\n",
    "    V.append(np.var(ctes))\n",
    "    ctes = []\n",
    "    \n",
    "#print(ctes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mupo = 2\n",
    "sigmapo = 0.2\n",
    "batch_size=100\n",
    "X = random.normal(mupo, sigmapo, 1000)\n",
    "x_batches = np.reshape(X, (10, batch_size)) \n",
    "\n",
    "H = []\n",
    "\n",
    "for i in range (50):\n",
    "    grad = NCEDescente1D(x_batches,mupo, sigmapo,mu_init = 24, sigma_init=4, cte_init = 0.2, learning_rate = [0.01,0.01], max_iters = 500, nu =x[i])\n",
    "    H.append(grad.cte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.plot(x,V)\n",
    "#print(V)\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.scatter(x,C)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remarques:\n",
    " * Lorsque nu diverge (i.e la taille du bruit est relativement importante par rapport √† celle de l'√©chantillon) le code semble se d√©bloquer et le NCE a une variance chaotique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cas 2: Loi du bruit\"raisonnablement\" distincte de celle de l'√©chantillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NCE \n",
    "\n",
    "mupo = 0.5\n",
    "sigmapo = 7\n",
    "batch_size=100\n",
    "X = random.normal(mupo, sigmapo, 1000)\n",
    "x_batches = np.reshape(X, (10, batch_size)) \n",
    "\n",
    "\n",
    "print(\"true constant value\" , 1/(sqrt(2*pi)*sigmapo))\n",
    "grad=NCE_Adam(x_batches,mupo, sigmapo,mu_init = 5, sigma_init=10, cte_init = 0.2, learning_rate = [0.01,0.01], max_iters = 500)    \n",
    "print(\"constant estimate\",grad.cte)\n",
    "\n",
    "print(\" nbre d'it√©rations\", len(grad.ctes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Calcul variance NCE\n",
    "\n",
    "mupo = 0.5\n",
    "sigmapo = 0.2\n",
    "batch_size=100\n",
    "X = random.normal(mupo, sigmapo, 1000)\n",
    "x_batches = np.reshape(X, (10, batch_size)) \n",
    "\n",
    "\n",
    "x= np.linspace(1,100,num=50)\n",
    "\n",
    "ctes=[]\n",
    "C=[]\n",
    "V=[]\n",
    "for i in range(len(x)):\n",
    "    \n",
    "    for j in range(10):\n",
    "        \n",
    "        grad = NCEDescent(x_batches,mupo, sigmapo,mu_init = 0.5, sigma_init=1, cte_init = 0.2, learning_rate = [0.01,0.01], max_iters = 200, nu =x[i])\n",
    "        #print(grad.m0)\n",
    "        ctes.append(grad.cte)\n",
    "    \n",
    "    C.append(np.mean(grad.cte))\n",
    "    V.append(np.var(ctes))\n",
    "    ctes = []\n",
    "    \n",
    "#print(ctes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calcul histogramme NCE \n",
    "\n",
    "mupo = 0.5\n",
    "sigmapo = 0.2\n",
    "batch_size=100\n",
    "X = random.normal(mupo, sigmapo, 1000)\n",
    "x_batches = np.reshape(X, (10, batch_size))\n",
    "\n",
    "H = []\n",
    "\n",
    "for i in range (50):\n",
    "    grad = NCEDescent(x_batches,mupo, sigmapo,mu_init = 0.5, sigma_init= 1, cte_init = 3, learning_rate = [0.01,0.01], max_iters = 500, nu = 1)\n",
    "    H.append(grad.cte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.plot(x,V)\n",
    "#print(V)\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.scatter(x,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remarques:\n",
    " * On remarque que conform√©ment au r√©sultat th√©orique. Lorsque nu diverge vers $+\\infty$ la variance du NCE diminue\n",
    " * L'estimateur ne semble pas biais√© d'apr√®s l'histogramme et variance relativement faible pour nu=1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAS 3: Bruit Tr√®s similaire √† l'√©chantillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##NCE \n",
    "\n",
    "mupo = 4 #we take  mu_noise = 5\n",
    "sigmapo = 7\n",
    "batch_size=100\n",
    "X = random.normal(mupo, sigmapo, 1000)\n",
    "x_batches = np.reshape(X, (10, batch_size)) \n",
    "\n",
    "print(\"true constant value\" , 1/(sqrt(2*pi)*sigmapo))\n",
    "\n",
    "grad=NCE_Adam(x_batches,mupo, sigmapo,mu_init = 5, sigma_init=7, cte_init = 3, learning_rate = [0.01,0.01], max_iters = 1000)    \n",
    "print(\"constant estimate\",grad.cte)\n",
    "\n",
    "print( \" nombres d'iterations \", len(grad.ctes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##NCE Variance en fonction de nu\n",
    "mupo = 0.5\n",
    "sigmapo = 1\n",
    "batch_size=100\n",
    "X = random.normal(mupo, sigmapo, 1000)\n",
    "x_batches = np.reshape(X, (10, batch_size)) \n",
    "\n",
    "\n",
    "x= np.linspace(1,100,num=50)\n",
    "\n",
    "ctes=[]\n",
    "C=[]\n",
    "V=[]\n",
    "\n",
    "for i in range(len(x)):\n",
    "    \n",
    "    for j in range(10):\n",
    "        \n",
    "        grad = NCEDescent(x_batches,mupo, sigmapo,mu_init = 5, sigma_init= 7, cte_init = 3, learning_rate = [0.01,0.01], max_iters = 200, nu =x[i])\n",
    "        #print(grad.m0)\n",
    "        ctes.append(grad.cte)\n",
    "    \n",
    "    C.append(np.mean(grad.cte))\n",
    "    V.append(np.var(ctes))\n",
    "    ctes = []\n",
    "    \n",
    "#print(ctes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Pr√©paration Histogramme de la constante pour nu=1, m_data= 0.5, s_data = 1, m_noise=5, s_noise=7\n",
    "\n",
    "mupo = 0.5\n",
    "sigmapo = 1\n",
    "batch_size=100\n",
    "X = random.normal(mupo, sigmapo, 1000)\n",
    "x_batches = np.reshape(X, (10, batch_size))\n",
    "\n",
    "H = []\n",
    "\n",
    "for i in range (50):\n",
    "    grad = NCEDescent1D(x_batches,mupo, sigmapo,mu_init = 5, sigma_init= 7, cte_init = 3, learning_rate = [0.01,0.01], max_iters = 500, nu = 1)\n",
    "    H.append(grad.cte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot:\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "fig.add_subplot(1,3,1)\n",
    "plt.plot(x,V)\n",
    "#print(V)\n",
    "fig.add_subplot(1,3,2)\n",
    "plt.scatter(x,C)\n",
    "fig.add_subplot(1,3,3)\n",
    "plt.hist(H)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remarques: Loi du bruit mod√©r√©ment √©loign√©e de la distribution initiale\n",
    " * On remarque que conform√©ment au r√©sultat th√©orique. Lorsque nu diverge vers $+\\infty$ la variance du NCE diminue\n",
    " * L'estimateur ne semble pas biais√© d'apr√®s l'histogramme et variance relativement faible pour nu=1.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN for estimation of a 1D density\n",
    "\n",
    "Generator is given by $G(z) = \\mu + \\sigma*z$ with$z ~ N(0,1)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GANDescent1D(x_batches, m, s,mu_init , sigma_init, cte_init , learning_rate = [0.01,0.01], max_iters = 500, nu=1):    \n",
    "    \n",
    "    m0 = mu_init \n",
    "    s0 =sigma_init\n",
    "    cte = cte_init\n",
    "    \n",
    "    error_mu = [] \n",
    "    error_sigma = []\n",
    "    error_cte = [] \n",
    "    \n",
    "    mus = [m0]\n",
    "    sigmas = [s0]\n",
    "    ctes = [cte]\n",
    "\n",
    "    batch_size= len(x_batches[0])\n",
    "     \n",
    "    for itr in range(max_iters): \n",
    "        \n",
    "        for x in x_batches:\n",
    "            \n",
    "            z= random.normal( 0, 1, int(batch_size)) \n",
    "            q = m0+s0*z\n",
    "            \n",
    "            #Gradient in respect to the constant\n",
    "            grad_cte = np.sum( 1/cte - pm0(x,m,s)/(cte*pm0(x,m,s)+ pn(x, m0,s0)) )/batch_size - (1/ batch_size)*np.sum( pm0(q,m,s)/(cte*pm0(q,m,s)+ pn(q,m0,s0)) )\n",
    "            cte = cte + learning_rate[0] * grad_cte\n",
    "            error_cte.append( (grad_cte) ) \n",
    "            \n",
    "\n",
    "            #Gradient in respect to noise parameters\n",
    "           \n",
    "            grad_mu = -(q-m0)/s0**2 +((q-m0)*norm.pdf(q, m0, s0)/s0**2 + \n",
    "                        (q-m)*cte*exp(-0.5*((q-m)/s)**2)/s**2)/(cte*pm0(q,m,s) + norm.pdf(q,m0,s0))\n",
    "            grad_sigma = grad_mu*z\n",
    "            \n",
    "            grad_mu = np.sum(grad_mu)/batch_size\n",
    "            grad_sigma = np.sum(grad_sigma)/batch_size\n",
    "            \n",
    "            m0 = m0 - learning_rate[1] * grad_mu\n",
    "            s0 = s0 - learning_rate[1] * grad_sigma\n",
    "            \n",
    "            error_mu.append( (grad_mu) ) \n",
    "            error_sigma.append((grad_sigma))\n",
    "            \n",
    "            ctes.append(cte)\n",
    "            mus.append(m0)\n",
    "            sigmas.append(s0)\n",
    "            \n",
    "            if ( abs(ctes[-1] - ctes[-2]) < 1e-6 and abs(mus[-1]-mus[-2])<1e-6 and abs(sigmas[-1]-sigmas[-2])<1e-6):\n",
    "                return Gradient(cte,m0,s0, error_mu,error_sigma, error_cte, ctes,mus,sigmas)\n",
    "            \n",
    "  \n",
    "    result = Gradient(cte,m0,s0, error_mu,error_sigma, error_cte, ctes,mus,sigmas)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets experiment GAN with different values of  $ùúá_{ùëëùëéùë°ùëé},ùúé_{ùëëùëéùë°ùëé},ùúá_{ùëõùëúùëñùë†ùëí},ùúé_{ùëõùëúùëñùë†ùëí}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mupo = 24\n",
    "sigmapo = 7\n",
    "batch_size=100\n",
    "X = random.normal(mupo, sigmapo, 1000)\n",
    "x_batches = np.reshape(X, (10, batch_size)) \n",
    "\n",
    "print(\"#########  With good learning rate for gen parameters ########\")\n",
    "\n",
    "grad=GANDescent(x_batches,mupo, sigmapo,mu_init = 5, sigma_init=0.2, cte_init = 0.2, learning_rate = [0.01,0.1], max_iters = 500)    \n",
    "print(\"constant estimate\",grad.cte)\n",
    "print(\"true constant value\" , 1/(sqrt(2*pi)*sigmapo))\n",
    "print(\"mu generaor \",grad.mu)\n",
    "print(\"sigma generaor \",grad.sigma)\n",
    "\n",
    "print(\"\\n #########  With bad learning rate for gen parameters #######\")\n",
    "\n",
    "grad=GANDescent(x_batches,mupo, sigmapo,mu_init = 5, sigma_init=0.2, cte_init = 0.2, learning_rate = [0.01,0.01], max_iters = 500)    \n",
    "print(\"constant estimate\",grad.cte)\n",
    "print(\"true constant value\" , 1/(sqrt(2*pi)*sigmapo))\n",
    "print(\"mu generaor \",grad.mu)\n",
    "print(\"sigma generaor \",grad.sigma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mupo = 24\n",
    "sigmapo = 0.2\n",
    "batch_size=100\n",
    "X = random.normal(mupo, sigmapo, 1000)\n",
    "x_batches = np.reshape(X, (10, batch_size)) \n",
    "\n",
    "### Problemes numeriques !!!!\n",
    "\n",
    "grad=GANDescent(x_batches,mupo, sigmapo,mu_init = 5, sigma_init=1, cte_init = 0.2, learning_rate = [0.01,0.1], max_iters = 800)    \n",
    "print(\"constant estimate\",grad.cte)\n",
    "print(\"true constant value\" , 1/(sqrt(2*pi)*sigmapo))\n",
    "print(\"mu generaor \",grad.mu)\n",
    "print(\"sigma generaor \",grad.sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad.error_cte[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm0(mupo,mupo,sigmapo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mupo = 0.5\n",
    "sigmapo = 0.2\n",
    "batch_size=100\n",
    "X = random.normal(mupo, sigmapo, 1000)\n",
    "x_batches = np.reshape(X, (10, batch_size)) \n",
    "\n",
    "\n",
    "\n",
    "grad=GANDescent(x_batches,mupo, sigmapo,mu_init = 5, sigma_init=1, cte_init = 0.2, learning_rate = [0.01,0.1], max_iters = 800)    \n",
    "print(\"constant estimate\",grad.cte)\n",
    "print(\"true constant value\" , 1/(sqrt(2*pi)*sigmapo))\n",
    "print(\"mu generaor \",grad.mu)\n",
    "print(\"sigma generaor \",grad.sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots and  Numerical Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mupo = 5\n",
    "sigmapo = 0.2\n",
    "batch_size=100\n",
    "X = random.normal(mupo, sigmapo, 1000)\n",
    "x_batches = np.reshape(X, (10, batch_size)) \n",
    "\n",
    "l=50\n",
    "MU = np.linspace(-10 , 10, num=l)\n",
    "\n",
    "nces = np.ones(l)\n",
    "\n",
    "for i in range(l):\n",
    "    grad=GANDescent(x_batches,mupo, sigmapo,mu_init = MU[i], sigma_init= sigmapo, cte_init = 0.2, learning_rate = [0.01,0.1], max_iters = 500)    \n",
    "    nces[i]= grad.cte\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(MU, nces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mupo = 5\n",
    "sigmapo = 0.2\n",
    "batch_size=100\n",
    "X = random.normal(mupo, sigmapo, 1000)\n",
    "x_batches = np.reshape(X, (10, batch_size)) \n",
    "\n",
    "l=200\n",
    "MU = np.linspace(-10 , 10, num=l)\n",
    "nces1 = np.ones(l)\n",
    "\n",
    "for i in range(l):\n",
    "    grad=NCEDescent(x_batches,mupo, sigmapo,mu_init = MU[i], sigma_init= sigmapo, cte_init = 0.2, learning_rate = [0.01,0.1], max_iters = 500)    \n",
    "\n",
    "    nces1[i]= grad.cte\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(MU, nces1)\n",
    "#plt.hist( nces1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mupo = 24\n",
    "sigmapo = 0.2\n",
    "batch_size=100\n",
    "X = random.normal(mupo, sigmapo, 1000)\n",
    "x_batches = np.reshape(X, (10, batch_size)) \n",
    "\n",
    "\n",
    "\n",
    "grad=NCEDescent1D(x_batches,mupo, sigmapo,mu_init = 24, sigma_init=0.2, cte_init = 0.2, learning_rate = 0.01, max_iters = 500)    \n",
    "print(\"constant estimate\",grad.cte)\n",
    "print(\"true constant value\" , 1/(sqrt(2*pi)*sigmapo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mupo = 0.5\n",
    "sigmapo = 7\n",
    "batch_size=100\n",
    "X = random.normal(mupo, sigmapo, 1000)\n",
    "x_batches = np.reshape(X, (10, batch_size)) \n",
    "\n",
    "\n",
    "\n",
    "grad=NCEDescent1D(x_batches,mupo, sigmapo,mu_init = 0.5, sigma_init=7, cte_init = 0.2, learning_rate = [0.01,0.01], max_iters = 500)    \n",
    "print(\"constant estimate\",grad.cte)\n",
    "print(\"true constant value\" , 1/(sqrt(2*pi)*sigmapo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mupo = 0.5 #we take  mu_noise = 5\n",
    "sigmapo = 7\n",
    "batch_size=100\n",
    "X = random.normal(mupo, sigmapo, 1000)\n",
    "x_batches = np.reshape(X, (10, batch_size)) \n",
    "\n",
    "\n",
    "\n",
    "grad=NCEDescent1D(x_batches,mupo, sigmapo,mu_init = 5, sigma_init=7, cte_init = 0.2, learning_rate = [0.01,0.01], max_iters = 500)    \n",
    "print(\"constant estimate\",grad.cte)\n",
    "print(\"true constant value\" , 1/(sqrt(2*pi)*sigmapo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mupo = 0.5 #we take  mu_noise = 5\n",
    "sigmapo = 7 #we take sigma_noise  = 5\n",
    "batch_size=100\n",
    "X = random.normal(mupo, sigmapo, 1000)\n",
    "x_batches = np.reshape(X, (10, batch_size)) \n",
    "\n",
    "\n",
    "\n",
    "grad=NCEDescent1D(x_batches,mupo, sigmapo,mu_init = 5, sigma_init=5, cte_init = 0.2, learning_rate = [0.01,0.01], max_iters = 500)    \n",
    "print(\"constant estimate\",grad.cte)\n",
    "print(\"true constant value\" , 1/(sqrt(2*pi)*sigmapo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cte = 1/(sqrt(2*pi)*0.2)\n",
    "cte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
