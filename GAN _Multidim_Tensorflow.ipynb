{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from math import pi\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from  sklearn import mixture\n",
    "import scipy.sparse\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import multivariate_normal\n",
    "tfd = tfp.distributions\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unnormalized Data Distribution\n",
    "def pm0(x, m, s):\n",
    "    mvn = tfd.MultivariateNormalFullCovariance(\n",
    "    loc=m,\n",
    "    covariance_matrix=s)\n",
    "    k = len(m)\n",
    "    return np.sqrt(np.linalg.det(s)*(2*pi)**k)*mvn.prob(x);\n",
    "\n",
    "# Noise Distribution\n",
    "def pn(x, m0, s0):\n",
    "    mvn = tfd.MultivariateNormalFullCovariance(\n",
    "    loc=m0,\n",
    "    covariance_matrix=s0)\n",
    "    \n",
    "    return mvn.prob(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This class is a helper that  will be instantiated in objects containing results from A Gradient Descent\n",
    "\n",
    "class Gradient:\n",
    "\n",
    "    # instance attribute\n",
    "    #Receive those attributes from\n",
    "    def __init__(self, cte,mu=[],sigma=[], error_mu =[],error_sigma=[], error_cte=[], ctes=[],mus=[],sigmas=[]):\n",
    "        self.cte = cte\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        self.error_mu = error_mu\n",
    "        self.error_sigma = error_sigma\n",
    "        self.error_cte = error_cte \n",
    "        \n",
    "        self.ctes = ctes\n",
    "        self.mus = mus\n",
    "        self.sigmas = sigmas\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_f2():  ##  Generator objective function\n",
    "    \n",
    "    g1= a*Z1 + b*Z2 + mu[0]\n",
    "    g2 = c*Z1 +  d*Z2 + mu[1]\n",
    "\n",
    "    g= tf.stack([g1,g2],1)\n",
    "\n",
    "\n",
    "    p_n = pn( g,m0, S) # noise (generator) density \n",
    "    p_m = pm0(g, m_data, s_data) #data density\n",
    "    \n",
    "    \n",
    "    temp = tf.math.reduce_mean( tf.math.log(p_n/(cte*p_m+p_n)))\n",
    "   \n",
    "    return tf.math.reduce_mean( tf.math.log(p_n/(cte*p_m+p_n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets experiment Grad descent for different values of $\\mu$ and $\\Sigma$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\envs\\memoiregan\\lib\\site-packages\\tensorflow_probability\\python\\distributions\\distribution.py:284: MultivariateNormalFullCovariance.__init__ (from tensorflow_probability.python.distributions.mvn_full_covariance) is deprecated and will be removed after 2019-12-01.\n",
      "Instructions for updating:\n",
      "`MultivariateNormalFullCovariance` is deprecated, use `MultivariateNormalTriL(loc=loc, scale_tril=tf.linalg.cholesky(covariance_matrix))` instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "######## GRADIENT DESCENT #############\n",
    "\n",
    "# d =2\n",
    "m_data = [1,2]\n",
    "s_data = [[5, 11], [11, 25]]\n",
    "\n",
    "####Cholesky gives : [1,2] [3,4]\n",
    "\n",
    "#Sampling X data\n",
    "batch_size=100\n",
    "x_batches = multivariate_normal.rvs(m_data, s_data, (10,batch_size))\n",
    "\n",
    "\n",
    "#Initial Values\n",
    "mu_init = [-4, 9]\n",
    "a,b =  tf.Variable((-2+ 1), dtype=\"float32\"), tf.Variable(-4+2, dtype=\"float32\"),\n",
    "c,d =  tf.Variable(3+3, dtype=\"float32\"), tf.Variable(1+ 4 ,dtype=\"float32\")\n",
    "cte_init = 1\n",
    "\n",
    "mu = tf.Variable(mu_init, dtype=\"float32\")\n",
    "\n",
    "cte = cte_init\n",
    "error_mu = [] \n",
    "error_sigma = []\n",
    "\n",
    "\n",
    "error_cte = [] \n",
    "mus = []\n",
    "sigmas = []\n",
    "\n",
    "\n",
    "ctes = []\n",
    "max_iters = 700\n",
    "learning_rate = 0.01\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    " \n",
    "for itr in range(max_iters): \n",
    "    #print(itr)\n",
    "    for x in x_batches:\n",
    "        ctes.append(cte)\n",
    "        Z1 = np.array(random.normal( 0, 1,batch_size)).astype(\"float32\")\n",
    "        Z2 = np.array(random.normal( 0, 1,batch_size)).astype(\"float32\")\n",
    "        \n",
    "        g1= a*Z1 + b*Z2 + mu[0]\n",
    "        g2 = c*Z1 +  d*Z2 + mu[1]\n",
    "\n",
    "        A = np.array([[a,b],[c,d]])\n",
    "        S = np.array(np.matmul(A , np.transpose(A))).astype(\"float32\")\n",
    "        \n",
    "        \n",
    "\n",
    "        g= np.stack([g1,g2],1)\n",
    "        \n",
    "       \n",
    "        \n",
    "        m0 = mu.numpy()\n",
    "        \n",
    "        p_nx = pn( x,m0, S).numpy() # noise (generator) density \n",
    "        p_mx = pm0(x, m_data, s_data).numpy() #data density\n",
    "\n",
    "        \n",
    "        p_ng = pn( g,m0, S).numpy() # noise (generator) density \n",
    "        p_mg = pm0(g, m_data, s_data).numpy() #data density\n",
    "\n",
    "        grad_cte = 1/cte - p_mx/(cte*p_mx+p_nx) -  p_mg/(cte*p_mg+p_ng)\n",
    "        grad_cte = np.sum(grad_cte)/batch_size\n",
    "            \n",
    "        cte = cte + 0.01*grad_cte\n",
    "        error_cte.append( (grad_cte) ) \n",
    "        if np.isnan(grad_cte):\n",
    "            break\n",
    "        opt.minimize(obj_f2, var_list=[ a,b,c,d,mu])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cte Estimate 0.07957740371823419\n",
      "True Value 0.0795774715459475\n",
      "\n",
      " Generator Cov Matrix \n",
      " [[ 5.0000005 11.000002 ]\n",
      " [11.000002  25.00001  ]]\n",
      "\n",
      " Mu Generator [0.9999995 2.0000002]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cte Estimate\" , cte)\n",
    "print(\"True Value\" ,1/np.sqrt(np.linalg.det(s_data)*(2*pi)**len(m_data)))\n",
    "\n",
    "A = [[a.numpy(),b.numpy()],[c.numpy(),d.numpy()]]\n",
    "\n",
    "print(\"\\n Generator Cov Matrix \\n\" , np.matmul(A, np.transpose(A)))\n",
    "\n",
    "print(\"\\n Mu Generator\" , mu.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed The Generator parameters converged to the data distribution parameters\n",
    "\n",
    "Lets try with other values of $\\mu$ $\\Sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## GRADIENT DESCENT #############\n",
    "\n",
    "# d =2\n",
    "m_data = [1,2]\n",
    "\n",
    "s_data = [[25, 39],\n",
    "       [39, 61]]\n",
    "\n",
    "# cholesky gives [3,4] [5, 6]\n",
    "# Sometimes Cholesky is not succesful\n",
    "\n",
    "#Sampling X data\n",
    "batch_size=100\n",
    "x_batches = multivariate_normal.rvs(m_data, s_data, (10,batch_size))\n",
    "\n",
    "\n",
    "#Initial Values\n",
    "mu_init = [-4, 9]\n",
    "a,b =  tf.Variable((-2+ 1), dtype=\"float32\"), tf.Variable(-4+2, dtype=\"float32\"),\n",
    "c,d =  tf.Variable(3+3, dtype=\"float32\"), tf.Variable(1+ 4 ,dtype=\"float32\")\n",
    "cte_init = 1\n",
    "\n",
    "mu = tf.Variable(mu_init, dtype=\"float32\")\n",
    "\n",
    "cte = cte_init\n",
    "error_mu = [] \n",
    "error_sigma = []\n",
    "\n",
    "\n",
    "error_cte = [] \n",
    "mus = []\n",
    "sigmas = []\n",
    "\n",
    "\n",
    "ctes = []\n",
    "max_iters = 700\n",
    "learning_rate = 0.01\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    " \n",
    "for itr in range(max_iters): \n",
    "    #print(itr)\n",
    "    for x in x_batches:\n",
    "        ctes.append(cte)\n",
    "        Z1 = np.array(random.normal( 0, 1,batch_size)).astype(\"float32\")\n",
    "        Z2 = np.array(random.normal( 0, 1,batch_size)).astype(\"float32\")\n",
    "        \n",
    "        g1= a*Z1 + b*Z2 + mu[0]\n",
    "        g2 = c*Z1 +  d*Z2 + mu[1]\n",
    "\n",
    "        A = np.array([[a,b],[c,d]])\n",
    "        S = np.array(np.matmul(A , np.transpose(A))).astype(\"float32\")\n",
    "        \n",
    "        \n",
    "\n",
    "        g= np.stack([g1,g2],1)\n",
    "        \n",
    "       \n",
    "        \n",
    "        m0 = mu.numpy()\n",
    "        \n",
    "        p_nx = pn( x,m0, S).numpy() # noise (generator) density \n",
    "        p_mx = pm0(x, m_data, s_data).numpy() #data density\n",
    "\n",
    "        \n",
    "        p_ng = pn( g,m0, S).numpy() # noise (generator) density \n",
    "        p_mg = pm0(g, m_data, s_data).numpy() #data density\n",
    "\n",
    "        grad_cte = 1/cte - p_mx/(cte*p_mx+p_nx) -  p_mg/(cte*p_mg+p_ng)\n",
    "        grad_cte = np.sum(grad_cte)/batch_size\n",
    "            \n",
    "        cte = cte + 0.01*grad_cte\n",
    "        error_cte.append( (grad_cte) ) \n",
    "        if np.isnan(grad_cte):\n",
    "            break\n",
    "        opt.minimize(obj_f2, var_list=[ a,b,c,d,mu])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cte Estimate 0.079576065646111\n",
      "True Value 0.07957747154594781\n",
      "\n",
      " Generator Cov Matrix \n",
      " [[24.999825 38.99974 ]\n",
      " [38.99974  60.999622]]\n",
      "\n",
      " Mu Generator [1.0030813 2.00482  ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Cte Estimate\" , cte)\n",
    "print(\"True Value\" ,1/np.sqrt(np.linalg.det(s_data)*(2*pi)**len(m_data)))\n",
    "\n",
    "A = [[a.numpy(),b.numpy()],[c.numpy(),d.numpy()]]\n",
    "\n",
    "print(\"\\n Generator Cov Matrix \\n\" , np.matmul(A, np.transpose(A)))\n",
    "\n",
    "print(\"\\n Mu Generator\" , mu.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
